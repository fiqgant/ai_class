{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Linear Regression • Logistic Regression • Regularisasi Ringan\n",
        "*Versi:* 2025-11-03 03:42:43\n\n",
        "Notebook ini **ramah pemula**: mulai dari konsep inti, rumus, lalu praktik dengan dataset publik.\n",
        "Semua transformasi dilakukan lewat **Pipeline** untuk menghindari **data leakage**.\n",
        "\n",
        "**Isi:**\n",
        "1) Linear Regression → MSE, solusi normal (mini), Ridge (L2)\n",
        "2) Logistic Regression → sigmoid, log-loss, evaluasi (F1/ROC)\n",
        "3) Regularisasi Ringan → L2 (Ridge/Logistic), L1 (opsional), Grid Search kecil\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A. Linear Regression — Intuisi & Rumus\n",
        "Prediksi target numerik $y$ dari fitur $\\mathbf{x}$:\n\n",
        "$$\\hat{y} = \\mathbf{w}^\\top \\mathbf{x} + b$$\n\n",
        "**Loss (MSE):**\n\n",
        "$$J(\\mathbf{w},b) = \\frac{1}{n}\\sum_{i=1}^{n}\\big(y_i - (\\mathbf{w}^\\top \\mathbf{x}_i + b)\\big)^2$$\n\n",
        "**Solusi normal (tanpa reguler):**\n\n",
        "$$\\mathbf{\\hat{w}} = (X^\\top X)^{-1}X^\\top \\mathbf{y}$$\n\n",
        "**Ridge (L2):**\n\n",
        "$$\\mathbf{\\hat{w}}_{\\mathrm{ridge}} = (X^\\top X + \\lambda I)^{-1}X^\\top \\mathbf{y}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Demo mini: solusi normal (2 fitur, data kecil)\n",
        "Kita buat 3 contoh data agar hitungan kecil bisa diverifikasi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# X with bias column handled separately (we'll augment later) for clarity\n",
        "X = np.array([[1.0, 2.0],\n",
        "              [2.0, 0.0],\n",
        "              [3.0, 1.0]])\n",
        "y = np.array([4.0, 1.0, 5.0])\n",
        "\n",
        "# add bias term by augmenting ones column\n",
        "X_aug = np.c_[X, np.ones(len(X))]\n",
        "w_hat = np.linalg.pinv(X_aug.T @ X_aug) @ (X_aug.T @ y)\n",
        "w_hat  # [w1, w2, b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Praktik: Ridge Regression (dataset Diabetes — publik scikit-learn)\n",
        "Kita pakai **Ridge (L2)** dengan **StandardScaler** dalam **Pipeline**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "ridge = make_pipeline(StandardScaler(), Ridge(alpha=1.0, random_state=42))\n",
        "ridge.fit(X_tr, y_tr)\n",
        "y_pr = ridge.predict(X_te)\n",
        "rmse = mean_squared_error(y_te, y_pr, squared=False)\n",
        "r2 = r2_score(y_te, y_pr)\n",
        "print({'RMSE': round(rmse,3), 'R2': round(r2,3)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Koefisien (setelah scaling)\n",
        "Kita tampilkan koefisien model untuk melihat fitur mana yang berpengaruh besar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Extract trained Ridge step & coef_ after scaling\n",
        "ridge_model = ridge.named_steps['ridge']\n",
        "coefs = ridge_model.coef_\n",
        "plt.figure()\n",
        "plt.bar(range(len(coefs)), coefs)\n",
        "plt.title('Koefisien Ridge (setelah scaling)')\n",
        "plt.xlabel('Fitur index')\n",
        "plt.ylabel('Koefisien')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B. Logistic Regression — Intuisi & Rumus\n",
        "Probabilitas kelas 1:\n\n",
        "$$p(y{=}1\\mid \\mathbf{x}) = \\sigma(z) = \\frac{1}{1+e^{-z}},\\quad z=\\mathbf{w}^\\top\\mathbf{x}+b$$\n\n",
        "**Log-loss (binary cross-entropy):**\n\n",
        "$$J(\\mathbf{w},b)=\\frac{1}{n}\\sum_{i=1}^{n}\\big(-y_i\\log p_i-(1-y_i)\\log(1-p_i)\\big)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Praktik: Logistic Regression (Breast Cancer — publik scikit-learn)\n",
        "Kita mulai dengan default **L2** (parameter `C=1.0`), **StandardScaler** dalam **Pipeline**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "logreg = make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000, C=1.0, random_state=42))\n",
        "logreg.fit(X_tr, y_tr)\n",
        "y_pr = logreg.predict(X_te)\n",
        "print(classification_report(y_te, y_pr))\n",
        "\n",
        "cm = confusion_matrix(y_te, y_pr)\n",
        "plt.figure()\n",
        "plt.imshow(cm)\n",
        "plt.title('Confusion Matrix — Logistic')\n",
        "plt.xlabel('Predicted'); plt.ylabel('True')\n",
        "for (i,j),v in __import__('numpy').ndenumerate(cm):\n",
        "    plt.text(j,i,str(v),ha='center',va='center')\n",
        "plt.colorbar(); plt.show()\n",
        "\n",
        "# ROC-AUC\n",
        "y_score = logreg.predict_proba(X_te)[:,1]\n",
        "auc = roc_auc_score(y_te, y_score)\n",
        "fpr, tpr, _ = roc_curve(y_te, y_score)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr)\n",
        "plt.plot([0,1],[0,1], linestyle='--')\n",
        "plt.title(f'ROC Curve (AUC={auc:.3f})')\n",
        "plt.xlabel('FPR'); plt.ylabel('TPR')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C. Regularisasi Ringan — L2 (Ridge/LR) & L1 (opsional)\n",
        "Kenapa reguler? Mengontrol **kompleksitas**, kurangi **overfitting**.\n",
        "- **L2 (Ridge/LR)**: menyeimbangkan bobot → kecil-mulus.\n",
        "- **L1 (Lasso)**: mendorong bobot ke **0** (seleksi fitur)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Perbandingan kecil Ridge (alpha) — CV=5\n",
        "Kita bandingkan `alpha ∈ {0.1, 1.0, 10.0}` dengan **cross_val_score**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "import pandas as pd\n",
        "\n",
        "alphas = [0.1, 1.0, 10.0]\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rows = []\n",
        "for a in alphas:\n",
        "    pipe = make_pipeline(StandardScaler(), Ridge(alpha=a, random_state=42))\n",
        "    scores = cross_val_score(pipe, X, y, cv=cv, scoring='neg_root_mean_squared_error')\n",
        "    rows.append({'alpha': a, 'rmse_mean': round(-scores.mean(),3), 'rmse_std': round(scores.std(),3)})\n",
        "df_ridge = pd.DataFrame(rows)\n",
        "from caas_jupyter_tools import display_dataframe_to_user\n",
        "display_dataframe_to_user('CV Ridge RMSE', df_ridge)\n",
        "df_ridge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Perbandingan kecil Logistic (C) — Stratified CV=5 (scoring=F1)\n",
        "Ingat: `C = 1/λ` → **C kecil = reguler kuat**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "C_list = [0.1, 1.0, 10.0]\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rows = []\n",
        "for C in C_list:\n",
        "    pipe = make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000, C=C, random_state=42))\n",
        "    scores = cross_val_score(pipe, X, y, cv=cv, scoring=make_scorer(f1_score))\n",
        "    rows.append({'C': C, 'f1_mean': round(scores.mean(),3), 'f1_std': round(scores.std(),3)})\n",
        "df_lr = pd.DataFrame(rows)\n",
        "from caas_jupyter_tools import display_dataframe_to_user\n",
        "display_dataframe_to_user('CV Logistic F1', df_lr)\n",
        "df_lr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Grid Search kecil (Logistic) — anti-leakage via Pipeline\n",
        "Grid: `C ∈ {0.1, 1.0, 10.0}` dengan **StratifiedKFold(5)**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "pipe = make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000, random_state=42))\n",
        "param_grid = {'logisticregression__C': [0.1, 1.0, 10.0]}\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "grid = GridSearchCV(pipe, param_grid, scoring='f1', cv=cv, n_jobs=-1)\n",
        "grid.fit(X_tr, y_tr)\n",
        "print('Best params:', grid.best_params_)\n",
        "print('CV best mean F1:', round(grid.best_score_,3))\n",
        "best = grid.best_estimator_\n",
        "from sklearn.metrics import f1_score\n",
        "print('Test F1:', round(f1_score(y_te, best.predict(X_te)),3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Catatan Imbalance — class_weight='balanced'\n",
        "Contoh cepat penggunaan `class_weight='balanced'` pada LogisticRegression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "bal = make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42))\n",
        "bal.fit(X_tr, y_tr)\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "y_pred_bal = bal.predict(X_te)\n",
        "p, r, f1, _ = precision_recall_fscore_support(y_te, y_pred_bal, average='binary')\n",
        "print({'precision': round(p,3), 'recall': round(r,3), 'f1': round(f1,3)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ringkasan\n",
        "- **Linear**: minimalkan MSE; gunakan **Ridge (L2)** untuk stabilitas.\n",
        "- **Logistic**: prediksi probabilitas; evaluasi dengan **F1/ROC-AUC**.\n",
        "- **Regularisasi**: L2 mengecilkan bobot, **C kecil** (Logistic) = reguler kuat.\n",
        "- **Pipeline & CV**: wajib untuk evaluasi adil dan anti-leakage.\n",
        "\n",
        "**Tugas Mini:**\n",
        "1) Coba `alpha ∈ {0.01, 0.1, 1, 10}` untuk Ridge; bandingkan RMSE (CV=5).\n",
        "2) Coba `C ∈ {0.01, 0.1, 1, 10}` untuk Logistic; bandingkan F1 (CV=5).\n",
        "3) Ubah threshold prediksi Logistic (bukan 0.5) dan lihat perubahan precision/recall."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}